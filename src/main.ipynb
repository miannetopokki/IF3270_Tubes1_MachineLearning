{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Lost Func (MSE)  11.12486772379277\n",
      "1 Lost Func (MSE)  10.217509086579007\n",
      "2 Lost Func (MSE)  9.384540409838085\n",
      "3 Lost Func (MSE)  8.664689967908203\n",
      "4 Lost Func (MSE)  8.066792585363343\n",
      "5 Lost Func (MSE)  7.5639062867269224\n",
      "6 Lost Func (MSE)  7.1263268322518\n",
      "7 Lost Func (MSE)  6.736183099548921\n",
      "8 Lost Func (MSE)  6.407625792705101\n",
      "9 Lost Func (MSE)  6.090082055960506\n",
      "10 Lost Func (MSE)  5.819451920515225\n",
      "11 Lost Func (MSE)  5.574475807233401\n",
      "12 Lost Func (MSE)  5.375872580574638\n",
      "13 Lost Func (MSE)  5.19832506024837\n",
      "14 Lost Func (MSE)  5.050916598725948\n",
      "15 Lost Func (MSE)  4.925091626896364\n",
      "16 Lost Func (MSE)  4.815481200077126\n",
      "17 Lost Func (MSE)  4.723612292771003\n",
      "18 Lost Func (MSE)  4.643319687065051\n",
      "19 Lost Func (MSE)  4.577265412149604\n",
      "20 Lost Func (MSE)  4.519166839094813\n",
      "21 Lost Func (MSE)  4.469561524971037\n",
      "22 Lost Func (MSE)  4.426331800102143\n",
      "23 Lost Func (MSE)  4.388823116727998\n",
      "24 Lost Func (MSE)  4.357235246616302\n",
      "25 Lost Func (MSE)  4.328209078998107\n",
      "26 Lost Func (MSE)  4.303070963451809\n",
      "27 Lost Func (MSE)  4.281017961793523\n",
      "28 Lost Func (MSE)  4.261512616343771\n",
      "29 Lost Func (MSE)  4.243933293246713\n",
      "30 Lost Func (MSE)  4.228206512112258\n",
      "31 Lost Func (MSE)  4.2141443120972415\n",
      "32 Lost Func (MSE)  4.201531126056172\n",
      "33 Lost Func (MSE)  4.1900149997454506\n",
      "34 Lost Func (MSE)  4.179529019796984\n",
      "35 Lost Func (MSE)  4.170168266460139\n",
      "36 Lost Func (MSE)  4.161471999562236\n",
      "37 Lost Func (MSE)  4.153763781828923\n",
      "38 Lost Func (MSE)  4.146486382146215\n",
      "39 Lost Func (MSE)  4.139926466062166\n",
      "40 Lost Func (MSE)  4.13364864580571\n",
      "41 Lost Func (MSE)  4.1280418540551755\n",
      "42 Lost Func (MSE)  4.122645088831678\n",
      "43 Lost Func (MSE)  4.117792318733408\n",
      "44 Lost Func (MSE)  4.113101984984365\n",
      "45 Lost Func (MSE)  4.108880113215414\n",
      "46 Lost Func (MSE)  4.104762756434899\n",
      "47 Lost Func (MSE)  4.101073237494145\n",
      "48 Lost Func (MSE)  4.097444876064974\n",
      "49 Lost Func (MSE)  4.094089184728265\n",
      "[Value(data=0.9949365595697391, grad=-0.010126880860521714), Value(data=-0.9187013397757562, grad=0.16259732044848763)]\n",
      "[Value(data=0.9999191207970104, grad=3.999838241594021), Value(data=0.9425179774673021, grad=-0.1149640450653957)]\n",
      "[Value(data=-0.9072444441469738, grad=0.1855111117060524), Value(data=0.8203043654228984, grad=-0.35939126915420316)]\n",
      "[Value(data=0.9416417545189573, grad=-0.11671649096208547), Value(data=-0.7995664637397626, grad=0.4008670725204748)]\n"
     ]
    }
   ],
   "source": [
    "from lib.MLP import MLP\n",
    "from lib.graph import draw_dot\n",
    "from lib.graph import draw_mlp\n",
    "\n",
    "\n",
    "#fitur, 3 input, 4 iterasi\n",
    "xs = [\n",
    "    [2.0,3.0,-1],\n",
    "    [3.0,-1.0,0.5],\n",
    "    [0.5,1.0,1.0],\n",
    "    [1.0,1.0,-1.0]\n",
    "]\n",
    "\n",
    "\n",
    "#label\n",
    "ys = [\n",
    "    [1.0, -1.0],\n",
    "    [-1.0, 1.0,],\n",
    "    [-1.0, 1.0],\n",
    "    [1.0, -1.0]\n",
    "]  #s\n",
    "\n",
    "\n",
    "\n",
    "input_layer = 3\n",
    "layer_f_activations = [\n",
    "  [2,'linear'],#hidden layer 1\n",
    "  [7,'relu'], #hidden layer 2\n",
    "  [2,'tanh'] #output layer\n",
    "]\n",
    "n = MLP(input_layer,[n[0] for n in layer_f_activations],activations=[n[1] for n in layer_f_activations])\n",
    "for i in range(50): #50 epoch\n",
    "\n",
    "\n",
    "  #Forward\n",
    "  ypred = [n(x) for x in xs]\n",
    "  #Sum rumus MSE\n",
    "  #Todo, Loss function yg lain\n",
    "  loss = sum([sum((yout_i - ygt_i)**2 for ygt_i, yout_i in zip(ygt, yout)) for ygt, yout in zip(ys, ypred)])\n",
    "\n",
    "  #flush bobot w\n",
    "  n.zero_grad()\n",
    "\n",
    "  ##Backward\n",
    "  loss.backward()\n",
    "  learning_rate =0.01\n",
    "\n",
    "\n",
    "  #gradient descent\n",
    "  for p in n.parameters():\n",
    "    #W + -lr*deltaW\n",
    "    p.data += -1 *learning_rate * p.grad\n",
    "\n",
    "  print(i,\"Lost Func (MSE) \" ,loss.data)\n",
    "\n",
    "for x in ypred:\n",
    "  print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph_output.dot.svg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_dot(loss).render(\"graph_output.dot\",view = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlp.dot.svg'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_mlp(n).render(\"mlp.dot\",view= True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
