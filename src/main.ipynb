{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.MLP import *\n",
    "from lib.graph import draw_dot\n",
    "from lib.graph import draw_mlp\n",
    "import random\n",
    "\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist Scikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn down for faster convergence\n",
    "t0 = time.time()\n",
    "train_samples = 5000\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "\n",
    "#Ngebantu ngacak urutan data, biar gk bias ke 0 soalnya mnist ngurut\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Shape X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn up tolerance for faster convergence\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "sparsity = np.mean(clf.coef_ == 0) * 100\n",
    "score = clf.score(X_test, y_test)\n",
    "# print('Best C % .4f' % clf.C_)\n",
    "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(clf.coef_[0], bins=20)\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.coef_.copy()\n",
    "plt.figure(figsize=(10, 5))\n",
    "scale = np.abs(coef).max()\n",
    "for i in range(10):\n",
    "    l1_plot = plt.subplot(2, 5, i + 1)\n",
    "    l1_plot.imshow(\n",
    "        coef[i].reshape(28, 28),\n",
    "        interpolation=\"nearest\",\n",
    "        cmap=plt.cm.RdBu,\n",
    "        vmin=-scale,\n",
    "        vmax=scale,\n",
    "    )\n",
    "    l1_plot.set_xticks(())\n",
    "    l1_plot.set_yticks(())\n",
    "    l1_plot.set_xlabel(\"Class %i\" % i)\n",
    "plt.suptitle(\"Classification vector for...\")\n",
    "\n",
    "run_time = time.time() - t0\n",
    "print(\"Example run in %.3f s\" % run_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dari OpenML\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "# Normalisasi (scaling agar lebih stabil)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data menjadi training & testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat model MLP\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', solver='adam',\n",
    "                    alpha=0.001, max_iter=20, random_state=42)\n",
    "\n",
    "# Training model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi pada data uji\n",
    "y_pred = mlp.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Akurasi\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Akurasi Model MLP: {accuracy:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 2\n",
    "sample_image = X_test[sample_idx].reshape(1, -1)  # Ambil satu sample\n",
    "proba = mlp.predict_proba(sample_image)[0]  # Ambil probabilitas dari output\n",
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilih satu gambar uji\n",
    "sample_idx = 2\n",
    "sample_image = X_test[sample_idx].reshape(1, -1)  # Ambil satu sample\n",
    "proba = mlp.predict_proba(sample_image)[0]  # Ambil probabilitas dari output\n",
    "\n",
    "# Plot Probabilitas Output\n",
    "plt.bar(range(10), proba)\n",
    "plt.xlabel(\"Digit (0-9)\")\n",
    "plt.ylabel(\"Probabilitas\")\n",
    "plt.title(\"Probabilitas Prediksi Model MLP Sklearn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "train_samples = 100\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "X = X / 255.0\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size=500\n",
    ")\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_encode = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_encode = encoder.transform(y_test.reshape(-1, 1))\n",
    "input_layer = X_train.shape[1]  # 784\n",
    "\n",
    "output_layer = 10  # MNIST punya 10 kelas (0-9)\n",
    "print(f\"Shape X_train: {X_train.shape}, y_train: {y_train_encode.shape}\")\n",
    "print(f\"Shape X_test: {X_test.shape}, y_test: {y_test_encode.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selected Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "X = X / 255.0\n",
    "random_state = check_random_state(0)\n",
    "y = y.astype(int)\n",
    "\n",
    "samples_per_class = 5\n",
    "selected_indices = []\n",
    "\n",
    "for digit in range(10):\n",
    "    indices = np.where(y == digit)[0]  \n",
    "    chosen = random_state.choice(indices, samples_per_class, replace=False)  \n",
    "    selected_indices.extend(chosen)\n",
    "\n",
    "X_train = X[selected_indices]\n",
    "y_train = y[selected_indices]\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_encode = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "print(f\"Shape X_train: {X_train.shape}, y_train: {y_train_encode.shape}\")\n",
    "print(\"Jumlah sampel per kelas:\", {i: np.sum(y_train == i) for i in range(10)})\n",
    "input_layer = X_train.shape[1] \n",
    "output_layer = 10  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reducted Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_f_activations = [\n",
    "  [8, 'tanh'], \n",
    "  [4, 'tanh'], \n",
    "  [output_layer, 'softmax'] \n",
    "]\n",
    "weight = Weight(\"uniform\", 42, input_layer,upper=1,lower =-1)  \n",
    "biasW = Weight(\"uniform\", 42, input_layer, upper=1, lower=1)  \n",
    "n = MLP(input_layer, [n[0] for n in layer_f_activations], activations=[n[1] for n in layer_f_activations], weight=weight,biasW=biasW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.fit_minibatch(x=X_train, y=y_train_encode, epoch=2, lossfunc=\"CCE\", learning_rate=0.1, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = MLP.load(\"model1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.save(filepath=\"tes.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correct_predictions = 0\n",
    "total_samples = len(X_train)\n",
    "\n",
    "for i in range(total_samples):\n",
    "    sample_vector = X_train[i].reshape(1, -1)  \n",
    "    ypred = n.predict(sample_vector)  \n",
    "\n",
    "    proba = [y_i.data for y in ypred for y_i in y]\n",
    "    predicted_class = np.argmax(proba) \n",
    "\n",
    "    if predicted_class == y_train[i]:\n",
    "        correct_predictions += 1\n",
    "        print(i)\n",
    "\n",
    "accuracy = (correct_predictions / total_samples) * 100\n",
    "print(f\"acc: {accuracy:.2f}% ({correct_predictions}/{total_samples})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "correct_predictions = 0\n",
    "total_samples = len(X_train)\n",
    "\n",
    "# Simpan jumlah prediksi tiap kelas\n",
    "predicted_class_counts = np.zeros(10, dtype=int)  # Untuk menyimpan distribusi kelas 0-9\n",
    "\n",
    "for i in range(total_samples):\n",
    "    sample_vector = X_train[i].reshape(1, -1)  \n",
    "    ypred = n.predict(sample_vector)  \n",
    "\n",
    "    # Ambil probabilitas dari prediksi\n",
    "    proba = [y_i.data for y in ypred for y_i in y]\n",
    "    \n",
    "    # Tentukan kelas dengan probabilitas tertinggi\n",
    "    predicted_class = np.argmax(proba)  \n",
    "    predicted_class_counts[predicted_class] += 1  # Tambahkan ke distribusi\n",
    "    \n",
    "    # Cek apakah prediksi benar\n",
    "    if predicted_class == y_train[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = (correct_predictions / total_samples) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}% ({correct_predictions}/{total_samples})\")\n",
    "\n",
    "# === Plot Distribusi Prediksi ===\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(10), predicted_class_counts, color=\"skyblue\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Predicted Classes\")\n",
    "plt.xticks(range(10))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_idx =1\n",
    "sample_image = X_train[sample_idx].reshape(14, 14) \n",
    "plt.imshow(sample_image, cmap=\"gray\")\n",
    "plt.title(f\"Sample Index: {sample_idx}\")\n",
    "plt.axis(\"off\")  \n",
    "plt.show()\n",
    "sample_image = X_train[sample_idx].reshape(1, -1) \n",
    "ypred = n.predict(sample_image)\n",
    "proba = []\n",
    "for y in ypred:\n",
    "    for y_i in y:\n",
    "        proba.append(y_i.data)\n",
    "        print(\"proba terbesar: \", max(proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(10),proba )\n",
    "plt.xlabel(\"dig\")\n",
    "plt.ylabel(\"prob\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = 500\n",
    "output_layer = 10\n",
    "batch_size = 500\n",
    "np.random.seed(42)\n",
    "x = np.random.uniform(-2,2,(batch_size,input_layer))\n",
    "y= np.random.uniform(0,2,(batch_size,output_layer))\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "print(\"Training X shape:\", X_train.shape)\n",
    "print(\"Validation Y shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = 3\n",
    "output_layer = 10\n",
    "batch_size = 100\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.normal(loc=0.5, scale=0.2, size=(batch_size, input_layer))  \n",
    "y_labels = np.random.randint(0, output_layer, size=batch_size).reshape(-1, 1)  \n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y = encoder.fit_transform(y_labels)  \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training X shape:\", X_train.shape)\n",
    "print(\"Validation X shape:\", X_val.shape)\n",
    "print(\"Training Y shape:\", y_train.shape)\n",
    "print(\"Validation Y shape:\", y_val.shape)\n",
    "print(\"Contoh y_train:\", y_train[:5])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_f_activations = [\n",
    "  [8,'relu'],\n",
    "  [4,'relu'],\n",
    "  [output_layer,'softmax']\n",
    "]\n",
    "weight = Weight(\"uniform\", 42,  lower=-1, upper=1)\n",
    "biasW = Weight(\"uniform\", 42,  lower=-0.1, upper=0.1)\n",
    "\n",
    "#kalau mau ada history valid  loss, masukin y_val dan x_val\n",
    "n = MLP(input_layer,[n[0] for n in layer_f_activations],activations=[n[1] for n in layer_f_activations],weight=weight,biasW=biasW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.fit_minibatch(x=X_train,y = y_train ,epoch=100,lossfunc=\"CCE\",learning_rate=0.1,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.fit_minibatch(x=X_train, y=y_train, epoch=20, lossfunc=\"CCE\", learning_rate=0.1, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.plot_W_distribution(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_mlp(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(mse).render(\"graph_output.dot\",view = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse._prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_mlp(n).render(\"mlp.dot\",view= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sz:  [3, 8, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "xs = [\n",
    "    [2.0,3.0,-1],\n",
    "    [3.0,-1.0,0.5],\n",
    "    [0.5,1.0,1.0],\n",
    "    [1.0,1.0,-1.0]\n",
    "]\n",
    "\n",
    "\n",
    "ys = [\n",
    "    [1.0 ],\n",
    "    [-1.0 ],\n",
    "    [-1.0],\n",
    "    [1.0 ]\n",
    "]  \n",
    "input_layer=3\n",
    "output_layer = 1\n",
    "\n",
    "\n",
    "layer_f_activations = [\n",
    "  [8, 'tanh'], \n",
    "  [4, 'tanh'], \n",
    "  [output_layer, 'tanh'] \n",
    "]\n",
    "\n",
    "\n",
    "n = MLP(input_layer, [n[0] for n in layer_f_activations], activations=[n[1] for n in layer_f_activations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [00:08<00:00, 119.15epoch/s, Train Loss=0.000316]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inputx : 3 MLP of [Layer of [TanhNeuron(3), TanhNeuron(3), TanhNeuron(3), TanhNeuron(3), TanhNeuron(3), TanhNeuron(3), TanhNeuron(3), TanhNeuron(3)], Layer of [TanhNeuron(8), TanhNeuron(8), TanhNeuron(8), TanhNeuron(8)], Layer of [TanhNeuron(4)]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fit(x=xs, y=ys, epoch=1000, lossfunc=\"MSE\", learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(2.0)\n",
    "b = Value(5.0)\n",
    "\n",
    "c = [3.0]\n",
    "\n",
    "ls = np.array([a,b])\n",
    "lx = np.array(c)\n",
    "\n",
    "print(ls + lx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
